{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-12T03:56:58.431790Z",
     "start_time": "2021-12-12T03:56:56.643473Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.utils import make_grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-12T03:56:58.441424Z",
     "start_time": "2021-12-12T03:56:58.433941Z"
    }
   },
   "outputs": [],
   "source": [
    "BATCH_SIZE = 32\n",
    "HIDDEN_SIZE = 256\n",
    "LOAD_MODEL = False\n",
    "USE_TRANSFER_LEARNING = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-12T03:56:58.450548Z",
     "start_time": "2021-12-12T03:56:58.444173Z"
    }
   },
   "outputs": [],
   "source": [
    "class Graph2VecEmbeddingsDataset(Dataset):\n",
    "    \"\"\"Graph2Vec Embeddings dataset.\"\"\"\n",
    "\n",
    "    def __init__(self, embeddings, labels=None, transform=None):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            embeddings (pd.dataframe): Pandas Dataframe with the graph2vec embeddings\n",
    "            labels : Labels indicating intelligence for the respective individual\n",
    "            transform (callable, optional): Optional transform to be applied\n",
    "                on a sample.\n",
    "        \"\"\"\n",
    "        self.embeddings = embeddings\n",
    "        self.labels = labels\n",
    "        self.transform = transforms.Compose([transforms.ToTensor()])\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.embeddings)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "\n",
    "        sample = torch.tensor(self.embeddings.iloc[idx]).float()\n",
    "\n",
    "        if self.labels is not None:\n",
    "            return sample, torch.tensor(self.labels.iloc[idx]).float()\n",
    "        else:\n",
    "            return sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_y = pd.read_csv(\"intelligence_label.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subjectkey</th>\n",
       "      <th>nihtbx_totalcomp_uncorrected</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NDARINV003RTV85</td>\n",
       "      <td>-0.790265</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NDARINV007W6H7B</td>\n",
       "      <td>-0.571433</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NDARINV00BD7VDC</td>\n",
       "      <td>0.632147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NDARINV00LJVZK2</td>\n",
       "      <td>0.194482</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NDARINV00NPMHND</td>\n",
       "      <td>-0.680849</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6907</th>\n",
       "      <td>NDARINVZZL0VA2F</td>\n",
       "      <td>-0.680849</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6908</th>\n",
       "      <td>NDARINVZZLZCKAY</td>\n",
       "      <td>-0.462016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6909</th>\n",
       "      <td>NDARINVZZPKBDAC</td>\n",
       "      <td>-0.680849</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6910</th>\n",
       "      <td>NDARINVZZZ2ALR6</td>\n",
       "      <td>-0.243184</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6911</th>\n",
       "      <td>NDARINVZZZNB0XC</td>\n",
       "      <td>0.632147</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6912 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           subjectkey  nihtbx_totalcomp_uncorrected\n",
       "0     NDARINV003RTV85                     -0.790265\n",
       "1     NDARINV007W6H7B                     -0.571433\n",
       "2     NDARINV00BD7VDC                      0.632147\n",
       "3     NDARINV00LJVZK2                      0.194482\n",
       "4     NDARINV00NPMHND                     -0.680849\n",
       "...               ...                           ...\n",
       "6907  NDARINVZZL0VA2F                     -0.680849\n",
       "6908  NDARINVZZLZCKAY                     -0.462016\n",
       "6909  NDARINVZZPKBDAC                     -0.680849\n",
       "6910  NDARINVZZZ2ALR6                     -0.243184\n",
       "6911  NDARINVZZZNB0XC                      0.632147\n",
       "\n",
       "[6912 rows x 2 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-12T03:56:58.543231Z",
     "start_time": "2021-12-12T03:56:58.452256Z"
    }
   },
   "outputs": [],
   "source": [
    "# Read data, make fake y and drop the \"type\" column\n",
    "\n",
    "#data = pd.read_csv(\"data/nci1.csv\")\n",
    "#data['y'] = np.random.normal(100,30, size=len(data))\n",
    "#data = data.drop(\"type\", axis=1)\n",
    "\n",
    "data = pd.read_csv(\"features/struct_embedding.csv\")\n",
    "#cols_to_norm = data.columns#.drop(\"y\")\n",
    "#data[cols_to_norm]=(data[cols_to_norm]-data[cols_to_norm].mean())/data[cols_to_norm].std()\n",
    "#data = data.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "subjid=data['type'].values[9].split('/')[-1].split('_')[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'NDARINV040B4TRC'"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['type'].values[9][-15:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/ubuntu/Stella/MLVU_multimodality/graph2vec/structural_graph_for_graph2vec_1212/graph2vec_structural_graph_NDARINV003RTV85'"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['type'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'NDARINV040B4TRC'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subjid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'NDARINV003RTV85'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_y['subjectkey'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = []\n",
    "for i in data['type']:\n",
    "    subjid = i.split('/')[-1].split('_')[-1]\n",
    "    for j in range(len(raw_y)):\n",
    "        if subjid == raw_y['subjectkey'][j]:\n",
    "            y.append(raw_y['nihtbx_totalcomp_uncorrected'][j])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2085"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>type</th>\n",
       "      <th>x_0</th>\n",
       "      <th>x_1</th>\n",
       "      <th>x_2</th>\n",
       "      <th>x_3</th>\n",
       "      <th>x_4</th>\n",
       "      <th>x_5</th>\n",
       "      <th>x_6</th>\n",
       "      <th>x_7</th>\n",
       "      <th>x_8</th>\n",
       "      <th>...</th>\n",
       "      <th>x_118</th>\n",
       "      <th>x_119</th>\n",
       "      <th>x_120</th>\n",
       "      <th>x_121</th>\n",
       "      <th>x_122</th>\n",
       "      <th>x_123</th>\n",
       "      <th>x_124</th>\n",
       "      <th>x_125</th>\n",
       "      <th>x_126</th>\n",
       "      <th>x_127</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>/home/ubuntu/Stella/MLVU_multimodality/graph2v...</td>\n",
       "      <td>-0.060564</td>\n",
       "      <td>-0.090097</td>\n",
       "      <td>0.017879</td>\n",
       "      <td>-0.233405</td>\n",
       "      <td>-0.031025</td>\n",
       "      <td>-0.161997</td>\n",
       "      <td>-0.110498</td>\n",
       "      <td>-0.106946</td>\n",
       "      <td>0.161249</td>\n",
       "      <td>...</td>\n",
       "      <td>0.154834</td>\n",
       "      <td>-0.357470</td>\n",
       "      <td>-0.041721</td>\n",
       "      <td>0.027009</td>\n",
       "      <td>0.074247</td>\n",
       "      <td>0.188864</td>\n",
       "      <td>-0.069622</td>\n",
       "      <td>-0.065493</td>\n",
       "      <td>-0.019565</td>\n",
       "      <td>-0.100768</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>/home/ubuntu/Stella/MLVU_multimodality/graph2v...</td>\n",
       "      <td>-0.058420</td>\n",
       "      <td>-0.086559</td>\n",
       "      <td>0.019345</td>\n",
       "      <td>-0.226949</td>\n",
       "      <td>-0.031319</td>\n",
       "      <td>-0.155380</td>\n",
       "      <td>-0.109569</td>\n",
       "      <td>-0.100978</td>\n",
       "      <td>0.149402</td>\n",
       "      <td>...</td>\n",
       "      <td>0.149971</td>\n",
       "      <td>-0.341140</td>\n",
       "      <td>-0.044229</td>\n",
       "      <td>0.026961</td>\n",
       "      <td>0.069826</td>\n",
       "      <td>0.183943</td>\n",
       "      <td>-0.067535</td>\n",
       "      <td>-0.063860</td>\n",
       "      <td>-0.019622</td>\n",
       "      <td>-0.093313</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>/home/ubuntu/Stella/MLVU_multimodality/graph2v...</td>\n",
       "      <td>-0.066414</td>\n",
       "      <td>-0.084501</td>\n",
       "      <td>0.019682</td>\n",
       "      <td>-0.234007</td>\n",
       "      <td>-0.033996</td>\n",
       "      <td>-0.160188</td>\n",
       "      <td>-0.116341</td>\n",
       "      <td>-0.105766</td>\n",
       "      <td>0.160227</td>\n",
       "      <td>...</td>\n",
       "      <td>0.154652</td>\n",
       "      <td>-0.353492</td>\n",
       "      <td>-0.039726</td>\n",
       "      <td>0.028335</td>\n",
       "      <td>0.074511</td>\n",
       "      <td>0.186440</td>\n",
       "      <td>-0.072687</td>\n",
       "      <td>-0.069850</td>\n",
       "      <td>-0.023465</td>\n",
       "      <td>-0.104869</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>/home/ubuntu/Stella/MLVU_multimodality/graph2v...</td>\n",
       "      <td>-0.061569</td>\n",
       "      <td>-0.079573</td>\n",
       "      <td>0.018303</td>\n",
       "      <td>-0.221120</td>\n",
       "      <td>-0.028189</td>\n",
       "      <td>-0.150833</td>\n",
       "      <td>-0.103980</td>\n",
       "      <td>-0.096945</td>\n",
       "      <td>0.152231</td>\n",
       "      <td>...</td>\n",
       "      <td>0.146012</td>\n",
       "      <td>-0.330881</td>\n",
       "      <td>-0.039162</td>\n",
       "      <td>0.021560</td>\n",
       "      <td>0.068880</td>\n",
       "      <td>0.172749</td>\n",
       "      <td>-0.061961</td>\n",
       "      <td>-0.060701</td>\n",
       "      <td>-0.015221</td>\n",
       "      <td>-0.097385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>/home/ubuntu/Stella/MLVU_multimodality/graph2v...</td>\n",
       "      <td>-0.063210</td>\n",
       "      <td>-0.087080</td>\n",
       "      <td>0.025141</td>\n",
       "      <td>-0.234608</td>\n",
       "      <td>-0.028360</td>\n",
       "      <td>-0.162248</td>\n",
       "      <td>-0.116670</td>\n",
       "      <td>-0.104763</td>\n",
       "      <td>0.154640</td>\n",
       "      <td>...</td>\n",
       "      <td>0.151280</td>\n",
       "      <td>-0.348356</td>\n",
       "      <td>-0.039079</td>\n",
       "      <td>0.024286</td>\n",
       "      <td>0.072855</td>\n",
       "      <td>0.182617</td>\n",
       "      <td>-0.066336</td>\n",
       "      <td>-0.065799</td>\n",
       "      <td>-0.023753</td>\n",
       "      <td>-0.103925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2080</th>\n",
       "      <td>/home/ubuntu/Stella/MLVU_multimodality/graph2v...</td>\n",
       "      <td>-0.052150</td>\n",
       "      <td>-0.077419</td>\n",
       "      <td>0.014720</td>\n",
       "      <td>-0.209189</td>\n",
       "      <td>-0.026127</td>\n",
       "      <td>-0.145545</td>\n",
       "      <td>-0.099978</td>\n",
       "      <td>-0.094635</td>\n",
       "      <td>0.141908</td>\n",
       "      <td>...</td>\n",
       "      <td>0.137550</td>\n",
       "      <td>-0.313037</td>\n",
       "      <td>-0.037452</td>\n",
       "      <td>0.020052</td>\n",
       "      <td>0.067365</td>\n",
       "      <td>0.168734</td>\n",
       "      <td>-0.060060</td>\n",
       "      <td>-0.064484</td>\n",
       "      <td>-0.016375</td>\n",
       "      <td>-0.086581</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2081</th>\n",
       "      <td>/home/ubuntu/Stella/MLVU_multimodality/graph2v...</td>\n",
       "      <td>-0.056559</td>\n",
       "      <td>-0.080355</td>\n",
       "      <td>0.022327</td>\n",
       "      <td>-0.229628</td>\n",
       "      <td>-0.029295</td>\n",
       "      <td>-0.160573</td>\n",
       "      <td>-0.113333</td>\n",
       "      <td>-0.101679</td>\n",
       "      <td>0.155368</td>\n",
       "      <td>...</td>\n",
       "      <td>0.149303</td>\n",
       "      <td>-0.339774</td>\n",
       "      <td>-0.042790</td>\n",
       "      <td>0.025548</td>\n",
       "      <td>0.072326</td>\n",
       "      <td>0.176757</td>\n",
       "      <td>-0.066028</td>\n",
       "      <td>-0.068545</td>\n",
       "      <td>-0.019505</td>\n",
       "      <td>-0.094861</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2082</th>\n",
       "      <td>/home/ubuntu/Stella/MLVU_multimodality/graph2v...</td>\n",
       "      <td>-0.059904</td>\n",
       "      <td>-0.084092</td>\n",
       "      <td>0.022182</td>\n",
       "      <td>-0.218934</td>\n",
       "      <td>-0.033377</td>\n",
       "      <td>-0.157618</td>\n",
       "      <td>-0.110358</td>\n",
       "      <td>-0.098928</td>\n",
       "      <td>0.148119</td>\n",
       "      <td>...</td>\n",
       "      <td>0.149383</td>\n",
       "      <td>-0.332917</td>\n",
       "      <td>-0.036531</td>\n",
       "      <td>0.026738</td>\n",
       "      <td>0.067816</td>\n",
       "      <td>0.179977</td>\n",
       "      <td>-0.069771</td>\n",
       "      <td>-0.069681</td>\n",
       "      <td>-0.022913</td>\n",
       "      <td>-0.093519</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2083</th>\n",
       "      <td>/home/ubuntu/Stella/MLVU_multimodality/graph2v...</td>\n",
       "      <td>-0.062419</td>\n",
       "      <td>-0.086961</td>\n",
       "      <td>0.018969</td>\n",
       "      <td>-0.241844</td>\n",
       "      <td>-0.030937</td>\n",
       "      <td>-0.168730</td>\n",
       "      <td>-0.120848</td>\n",
       "      <td>-0.102684</td>\n",
       "      <td>0.162021</td>\n",
       "      <td>...</td>\n",
       "      <td>0.152759</td>\n",
       "      <td>-0.365104</td>\n",
       "      <td>-0.042149</td>\n",
       "      <td>0.024744</td>\n",
       "      <td>0.076086</td>\n",
       "      <td>0.194581</td>\n",
       "      <td>-0.067730</td>\n",
       "      <td>-0.070011</td>\n",
       "      <td>-0.015568</td>\n",
       "      <td>-0.100741</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2084</th>\n",
       "      <td>/home/ubuntu/Stella/MLVU_multimodality/graph2v...</td>\n",
       "      <td>-0.061167</td>\n",
       "      <td>-0.087081</td>\n",
       "      <td>0.017005</td>\n",
       "      <td>-0.221845</td>\n",
       "      <td>-0.031672</td>\n",
       "      <td>-0.159279</td>\n",
       "      <td>-0.111235</td>\n",
       "      <td>-0.100327</td>\n",
       "      <td>0.156237</td>\n",
       "      <td>...</td>\n",
       "      <td>0.149118</td>\n",
       "      <td>-0.338900</td>\n",
       "      <td>-0.043286</td>\n",
       "      <td>0.025112</td>\n",
       "      <td>0.065961</td>\n",
       "      <td>0.175440</td>\n",
       "      <td>-0.064622</td>\n",
       "      <td>-0.065419</td>\n",
       "      <td>-0.020433</td>\n",
       "      <td>-0.091969</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2085 rows × 129 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   type       x_0       x_1  \\\n",
       "0     /home/ubuntu/Stella/MLVU_multimodality/graph2v... -0.060564 -0.090097   \n",
       "1     /home/ubuntu/Stella/MLVU_multimodality/graph2v... -0.058420 -0.086559   \n",
       "2     /home/ubuntu/Stella/MLVU_multimodality/graph2v... -0.066414 -0.084501   \n",
       "3     /home/ubuntu/Stella/MLVU_multimodality/graph2v... -0.061569 -0.079573   \n",
       "4     /home/ubuntu/Stella/MLVU_multimodality/graph2v... -0.063210 -0.087080   \n",
       "...                                                 ...       ...       ...   \n",
       "2080  /home/ubuntu/Stella/MLVU_multimodality/graph2v... -0.052150 -0.077419   \n",
       "2081  /home/ubuntu/Stella/MLVU_multimodality/graph2v... -0.056559 -0.080355   \n",
       "2082  /home/ubuntu/Stella/MLVU_multimodality/graph2v... -0.059904 -0.084092   \n",
       "2083  /home/ubuntu/Stella/MLVU_multimodality/graph2v... -0.062419 -0.086961   \n",
       "2084  /home/ubuntu/Stella/MLVU_multimodality/graph2v... -0.061167 -0.087081   \n",
       "\n",
       "           x_2       x_3       x_4       x_5       x_6       x_7       x_8  \\\n",
       "0     0.017879 -0.233405 -0.031025 -0.161997 -0.110498 -0.106946  0.161249   \n",
       "1     0.019345 -0.226949 -0.031319 -0.155380 -0.109569 -0.100978  0.149402   \n",
       "2     0.019682 -0.234007 -0.033996 -0.160188 -0.116341 -0.105766  0.160227   \n",
       "3     0.018303 -0.221120 -0.028189 -0.150833 -0.103980 -0.096945  0.152231   \n",
       "4     0.025141 -0.234608 -0.028360 -0.162248 -0.116670 -0.104763  0.154640   \n",
       "...        ...       ...       ...       ...       ...       ...       ...   \n",
       "2080  0.014720 -0.209189 -0.026127 -0.145545 -0.099978 -0.094635  0.141908   \n",
       "2081  0.022327 -0.229628 -0.029295 -0.160573 -0.113333 -0.101679  0.155368   \n",
       "2082  0.022182 -0.218934 -0.033377 -0.157618 -0.110358 -0.098928  0.148119   \n",
       "2083  0.018969 -0.241844 -0.030937 -0.168730 -0.120848 -0.102684  0.162021   \n",
       "2084  0.017005 -0.221845 -0.031672 -0.159279 -0.111235 -0.100327  0.156237   \n",
       "\n",
       "      ...     x_118     x_119     x_120     x_121     x_122     x_123  \\\n",
       "0     ...  0.154834 -0.357470 -0.041721  0.027009  0.074247  0.188864   \n",
       "1     ...  0.149971 -0.341140 -0.044229  0.026961  0.069826  0.183943   \n",
       "2     ...  0.154652 -0.353492 -0.039726  0.028335  0.074511  0.186440   \n",
       "3     ...  0.146012 -0.330881 -0.039162  0.021560  0.068880  0.172749   \n",
       "4     ...  0.151280 -0.348356 -0.039079  0.024286  0.072855  0.182617   \n",
       "...   ...       ...       ...       ...       ...       ...       ...   \n",
       "2080  ...  0.137550 -0.313037 -0.037452  0.020052  0.067365  0.168734   \n",
       "2081  ...  0.149303 -0.339774 -0.042790  0.025548  0.072326  0.176757   \n",
       "2082  ...  0.149383 -0.332917 -0.036531  0.026738  0.067816  0.179977   \n",
       "2083  ...  0.152759 -0.365104 -0.042149  0.024744  0.076086  0.194581   \n",
       "2084  ...  0.149118 -0.338900 -0.043286  0.025112  0.065961  0.175440   \n",
       "\n",
       "         x_124     x_125     x_126     x_127  \n",
       "0    -0.069622 -0.065493 -0.019565 -0.100768  \n",
       "1    -0.067535 -0.063860 -0.019622 -0.093313  \n",
       "2    -0.072687 -0.069850 -0.023465 -0.104869  \n",
       "3    -0.061961 -0.060701 -0.015221 -0.097385  \n",
       "4    -0.066336 -0.065799 -0.023753 -0.103925  \n",
       "...        ...       ...       ...       ...  \n",
       "2080 -0.060060 -0.064484 -0.016375 -0.086581  \n",
       "2081 -0.066028 -0.068545 -0.019505 -0.094861  \n",
       "2082 -0.069771 -0.069681 -0.022913 -0.093519  \n",
       "2083 -0.067730 -0.070011 -0.015568 -0.100741  \n",
       "2084 -0.064622 -0.065419 -0.020433 -0.091969  \n",
       "\n",
       "[2085 rows x 129 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['y'] = y\n",
    "data = data.drop(\"type\", axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x_0</th>\n",
       "      <th>x_1</th>\n",
       "      <th>x_2</th>\n",
       "      <th>x_3</th>\n",
       "      <th>x_4</th>\n",
       "      <th>x_5</th>\n",
       "      <th>x_6</th>\n",
       "      <th>x_7</th>\n",
       "      <th>x_8</th>\n",
       "      <th>x_9</th>\n",
       "      <th>...</th>\n",
       "      <th>x_119</th>\n",
       "      <th>x_120</th>\n",
       "      <th>x_121</th>\n",
       "      <th>x_122</th>\n",
       "      <th>x_123</th>\n",
       "      <th>x_124</th>\n",
       "      <th>x_125</th>\n",
       "      <th>x_126</th>\n",
       "      <th>x_127</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.060564</td>\n",
       "      <td>-0.090097</td>\n",
       "      <td>0.017879</td>\n",
       "      <td>-0.233405</td>\n",
       "      <td>-0.031025</td>\n",
       "      <td>-0.161997</td>\n",
       "      <td>-0.110498</td>\n",
       "      <td>-0.106946</td>\n",
       "      <td>0.161249</td>\n",
       "      <td>-0.466659</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.357470</td>\n",
       "      <td>-0.041721</td>\n",
       "      <td>0.027009</td>\n",
       "      <td>0.074247</td>\n",
       "      <td>0.188864</td>\n",
       "      <td>-0.069622</td>\n",
       "      <td>-0.065493</td>\n",
       "      <td>-0.019565</td>\n",
       "      <td>-0.100768</td>\n",
       "      <td>-0.790265</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.058420</td>\n",
       "      <td>-0.086559</td>\n",
       "      <td>0.019345</td>\n",
       "      <td>-0.226949</td>\n",
       "      <td>-0.031319</td>\n",
       "      <td>-0.155380</td>\n",
       "      <td>-0.109569</td>\n",
       "      <td>-0.100978</td>\n",
       "      <td>0.149402</td>\n",
       "      <td>-0.449210</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.341140</td>\n",
       "      <td>-0.044229</td>\n",
       "      <td>0.026961</td>\n",
       "      <td>0.069826</td>\n",
       "      <td>0.183943</td>\n",
       "      <td>-0.067535</td>\n",
       "      <td>-0.063860</td>\n",
       "      <td>-0.019622</td>\n",
       "      <td>-0.093313</td>\n",
       "      <td>-0.680849</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.066414</td>\n",
       "      <td>-0.084501</td>\n",
       "      <td>0.019682</td>\n",
       "      <td>-0.234007</td>\n",
       "      <td>-0.033996</td>\n",
       "      <td>-0.160188</td>\n",
       "      <td>-0.116341</td>\n",
       "      <td>-0.105766</td>\n",
       "      <td>0.160227</td>\n",
       "      <td>-0.463173</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.353492</td>\n",
       "      <td>-0.039726</td>\n",
       "      <td>0.028335</td>\n",
       "      <td>0.074511</td>\n",
       "      <td>0.186440</td>\n",
       "      <td>-0.072687</td>\n",
       "      <td>-0.069850</td>\n",
       "      <td>-0.023465</td>\n",
       "      <td>-0.104869</td>\n",
       "      <td>0.632147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.061569</td>\n",
       "      <td>-0.079573</td>\n",
       "      <td>0.018303</td>\n",
       "      <td>-0.221120</td>\n",
       "      <td>-0.028189</td>\n",
       "      <td>-0.150833</td>\n",
       "      <td>-0.103980</td>\n",
       "      <td>-0.096945</td>\n",
       "      <td>0.152231</td>\n",
       "      <td>-0.431845</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.330881</td>\n",
       "      <td>-0.039162</td>\n",
       "      <td>0.021560</td>\n",
       "      <td>0.068880</td>\n",
       "      <td>0.172749</td>\n",
       "      <td>-0.061961</td>\n",
       "      <td>-0.060701</td>\n",
       "      <td>-0.015221</td>\n",
       "      <td>-0.097385</td>\n",
       "      <td>-0.133767</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.063210</td>\n",
       "      <td>-0.087080</td>\n",
       "      <td>0.025141</td>\n",
       "      <td>-0.234608</td>\n",
       "      <td>-0.028360</td>\n",
       "      <td>-0.162248</td>\n",
       "      <td>-0.116670</td>\n",
       "      <td>-0.104763</td>\n",
       "      <td>0.154640</td>\n",
       "      <td>-0.459196</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.348356</td>\n",
       "      <td>-0.039079</td>\n",
       "      <td>0.024286</td>\n",
       "      <td>0.072855</td>\n",
       "      <td>0.182617</td>\n",
       "      <td>-0.066336</td>\n",
       "      <td>-0.065799</td>\n",
       "      <td>-0.023753</td>\n",
       "      <td>-0.103925</td>\n",
       "      <td>-0.243184</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2080</th>\n",
       "      <td>-0.052150</td>\n",
       "      <td>-0.077419</td>\n",
       "      <td>0.014720</td>\n",
       "      <td>-0.209189</td>\n",
       "      <td>-0.026127</td>\n",
       "      <td>-0.145545</td>\n",
       "      <td>-0.099978</td>\n",
       "      <td>-0.094635</td>\n",
       "      <td>0.141908</td>\n",
       "      <td>-0.413155</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.313037</td>\n",
       "      <td>-0.037452</td>\n",
       "      <td>0.020052</td>\n",
       "      <td>0.067365</td>\n",
       "      <td>0.168734</td>\n",
       "      <td>-0.060060</td>\n",
       "      <td>-0.064484</td>\n",
       "      <td>-0.016375</td>\n",
       "      <td>-0.086581</td>\n",
       "      <td>0.194482</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2081</th>\n",
       "      <td>-0.056559</td>\n",
       "      <td>-0.080355</td>\n",
       "      <td>0.022327</td>\n",
       "      <td>-0.229628</td>\n",
       "      <td>-0.029295</td>\n",
       "      <td>-0.160573</td>\n",
       "      <td>-0.113333</td>\n",
       "      <td>-0.101679</td>\n",
       "      <td>0.155368</td>\n",
       "      <td>-0.451812</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.339774</td>\n",
       "      <td>-0.042790</td>\n",
       "      <td>0.025548</td>\n",
       "      <td>0.072326</td>\n",
       "      <td>0.176757</td>\n",
       "      <td>-0.066028</td>\n",
       "      <td>-0.068545</td>\n",
       "      <td>-0.019505</td>\n",
       "      <td>-0.094861</td>\n",
       "      <td>1.179229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2082</th>\n",
       "      <td>-0.059904</td>\n",
       "      <td>-0.084092</td>\n",
       "      <td>0.022182</td>\n",
       "      <td>-0.218934</td>\n",
       "      <td>-0.033377</td>\n",
       "      <td>-0.157618</td>\n",
       "      <td>-0.110358</td>\n",
       "      <td>-0.098928</td>\n",
       "      <td>0.148119</td>\n",
       "      <td>-0.439615</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.332917</td>\n",
       "      <td>-0.036531</td>\n",
       "      <td>0.026738</td>\n",
       "      <td>0.067816</td>\n",
       "      <td>0.179977</td>\n",
       "      <td>-0.069771</td>\n",
       "      <td>-0.069681</td>\n",
       "      <td>-0.022913</td>\n",
       "      <td>-0.093519</td>\n",
       "      <td>-0.462016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2083</th>\n",
       "      <td>-0.062419</td>\n",
       "      <td>-0.086961</td>\n",
       "      <td>0.018969</td>\n",
       "      <td>-0.241844</td>\n",
       "      <td>-0.030937</td>\n",
       "      <td>-0.168730</td>\n",
       "      <td>-0.120848</td>\n",
       "      <td>-0.102684</td>\n",
       "      <td>0.162021</td>\n",
       "      <td>-0.471974</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.365104</td>\n",
       "      <td>-0.042149</td>\n",
       "      <td>0.024744</td>\n",
       "      <td>0.076086</td>\n",
       "      <td>0.194581</td>\n",
       "      <td>-0.067730</td>\n",
       "      <td>-0.070011</td>\n",
       "      <td>-0.015568</td>\n",
       "      <td>-0.100741</td>\n",
       "      <td>-0.024351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2084</th>\n",
       "      <td>-0.061167</td>\n",
       "      <td>-0.087081</td>\n",
       "      <td>0.017005</td>\n",
       "      <td>-0.221845</td>\n",
       "      <td>-0.031672</td>\n",
       "      <td>-0.159279</td>\n",
       "      <td>-0.111235</td>\n",
       "      <td>-0.100327</td>\n",
       "      <td>0.156237</td>\n",
       "      <td>-0.444921</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.338900</td>\n",
       "      <td>-0.043286</td>\n",
       "      <td>0.025112</td>\n",
       "      <td>0.065961</td>\n",
       "      <td>0.175440</td>\n",
       "      <td>-0.064622</td>\n",
       "      <td>-0.065419</td>\n",
       "      <td>-0.020433</td>\n",
       "      <td>-0.091969</td>\n",
       "      <td>0.632147</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2085 rows × 129 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           x_0       x_1       x_2       x_3       x_4       x_5       x_6  \\\n",
       "0    -0.060564 -0.090097  0.017879 -0.233405 -0.031025 -0.161997 -0.110498   \n",
       "1    -0.058420 -0.086559  0.019345 -0.226949 -0.031319 -0.155380 -0.109569   \n",
       "2    -0.066414 -0.084501  0.019682 -0.234007 -0.033996 -0.160188 -0.116341   \n",
       "3    -0.061569 -0.079573  0.018303 -0.221120 -0.028189 -0.150833 -0.103980   \n",
       "4    -0.063210 -0.087080  0.025141 -0.234608 -0.028360 -0.162248 -0.116670   \n",
       "...        ...       ...       ...       ...       ...       ...       ...   \n",
       "2080 -0.052150 -0.077419  0.014720 -0.209189 -0.026127 -0.145545 -0.099978   \n",
       "2081 -0.056559 -0.080355  0.022327 -0.229628 -0.029295 -0.160573 -0.113333   \n",
       "2082 -0.059904 -0.084092  0.022182 -0.218934 -0.033377 -0.157618 -0.110358   \n",
       "2083 -0.062419 -0.086961  0.018969 -0.241844 -0.030937 -0.168730 -0.120848   \n",
       "2084 -0.061167 -0.087081  0.017005 -0.221845 -0.031672 -0.159279 -0.111235   \n",
       "\n",
       "           x_7       x_8       x_9  ...     x_119     x_120     x_121  \\\n",
       "0    -0.106946  0.161249 -0.466659  ... -0.357470 -0.041721  0.027009   \n",
       "1    -0.100978  0.149402 -0.449210  ... -0.341140 -0.044229  0.026961   \n",
       "2    -0.105766  0.160227 -0.463173  ... -0.353492 -0.039726  0.028335   \n",
       "3    -0.096945  0.152231 -0.431845  ... -0.330881 -0.039162  0.021560   \n",
       "4    -0.104763  0.154640 -0.459196  ... -0.348356 -0.039079  0.024286   \n",
       "...        ...       ...       ...  ...       ...       ...       ...   \n",
       "2080 -0.094635  0.141908 -0.413155  ... -0.313037 -0.037452  0.020052   \n",
       "2081 -0.101679  0.155368 -0.451812  ... -0.339774 -0.042790  0.025548   \n",
       "2082 -0.098928  0.148119 -0.439615  ... -0.332917 -0.036531  0.026738   \n",
       "2083 -0.102684  0.162021 -0.471974  ... -0.365104 -0.042149  0.024744   \n",
       "2084 -0.100327  0.156237 -0.444921  ... -0.338900 -0.043286  0.025112   \n",
       "\n",
       "         x_122     x_123     x_124     x_125     x_126     x_127         y  \n",
       "0     0.074247  0.188864 -0.069622 -0.065493 -0.019565 -0.100768 -0.790265  \n",
       "1     0.069826  0.183943 -0.067535 -0.063860 -0.019622 -0.093313 -0.680849  \n",
       "2     0.074511  0.186440 -0.072687 -0.069850 -0.023465 -0.104869  0.632147  \n",
       "3     0.068880  0.172749 -0.061961 -0.060701 -0.015221 -0.097385 -0.133767  \n",
       "4     0.072855  0.182617 -0.066336 -0.065799 -0.023753 -0.103925 -0.243184  \n",
       "...        ...       ...       ...       ...       ...       ...       ...  \n",
       "2080  0.067365  0.168734 -0.060060 -0.064484 -0.016375 -0.086581  0.194482  \n",
       "2081  0.072326  0.176757 -0.066028 -0.068545 -0.019505 -0.094861  1.179229  \n",
       "2082  0.067816  0.179977 -0.069771 -0.069681 -0.022913 -0.093519 -0.462016  \n",
       "2083  0.076086  0.194581 -0.067730 -0.070011 -0.015568 -0.100741 -0.024351  \n",
       "2084  0.065961  0.175440 -0.064622 -0.065419 -0.020433 -0.091969  0.632147  \n",
       "\n",
       "[2085 rows x 129 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-12T03:56:58.555167Z",
     "start_time": "2021-12-12T03:56:58.544714Z"
    }
   },
   "outputs": [],
   "source": [
    "train_df, test_df = np.split(data.sample(frac=1, random_state=42), [int(.9*len(data))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-12T03:56:58.565155Z",
     "start_time": "2021-12-12T03:56:58.557406Z"
    }
   },
   "outputs": [],
   "source": [
    "X_train, X_valid, y_train, y_valid = \\\n",
    "    train_test_split(train_df.iloc[:, 1:], train_df['y'], test_size=1/9, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-12T03:56:58.575067Z",
     "start_time": "2021-12-12T03:56:58.569068Z"
    }
   },
   "outputs": [],
   "source": [
    "y_test = test_df[\"y\"]\n",
    "X_test = test_df.drop(\"y\", axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-12T03:56:58.583376Z",
     "start_time": "2021-12-12T03:56:58.578275Z"
    }
   },
   "outputs": [],
   "source": [
    "train_dataset = Graph2VecEmbeddingsDataset(embeddings=X_train, labels=y_train)\n",
    "valid_dataset = Graph2VecEmbeddingsDataset(embeddings=X_valid, labels=y_valid)\n",
    "test_dataset = Graph2VecEmbeddingsDataset(embeddings=X_test, labels=y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-12T03:56:58.598531Z",
     "start_time": "2021-12-12T03:56:58.585628Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([-0.0791,  0.0202, -0.2237, -0.0260, -0.1540, -0.1060, -0.0978,  0.1563,\n",
       "         -0.4445, -0.1577,  0.1053,  0.1649, -0.1205, -0.0182, -0.0742,  0.1317,\n",
       "         -0.0133, -0.0345,  0.0189,  0.0866, -0.0362, -0.1538, -0.0870,  0.1135,\n",
       "          0.1484, -0.0689,  0.1210, -0.0928, -0.2405,  0.0363,  0.0832,  0.2093,\n",
       "          0.1253,  0.1266,  0.0497,  0.1993,  0.0338,  0.0106, -0.0174, -0.0405,\n",
       "          0.0585, -0.0139, -0.1354,  0.0111,  0.0802, -0.0885,  0.0314,  0.1998,\n",
       "         -0.1191,  0.0556,  0.0351, -0.0290,  0.1275,  0.0684, -0.0505, -0.0972,\n",
       "         -0.0658, -0.1896,  0.0479,  0.1226,  0.1327,  0.1130, -0.2914,  0.1589,\n",
       "          0.0283, -0.1357,  0.0391,  0.0880,  0.1169, -0.0051, -0.0266, -0.0902,\n",
       "         -0.1583,  0.0262,  0.0880, -0.2065, -0.0679,  0.0869,  0.3149, -0.0436,\n",
       "         -0.3597, -0.0374, -0.1253,  0.0345, -0.0969, -0.1100, -0.1059,  0.0954,\n",
       "          0.0550, -0.1455, -0.0723,  0.0213,  0.0611, -0.2990,  0.0313, -0.0987,\n",
       "          0.0367, -0.0379, -0.1690, -0.0547,  0.0230,  0.1043, -0.2494,  0.0051,\n",
       "          0.4328, -0.0105,  0.0705,  0.1023, -0.0250,  0.0087,  0.0357,  0.1179,\n",
       "          0.0068,  0.0017,  0.0840, -0.1162,  0.0924,  0.1442, -0.3394, -0.0395,\n",
       "          0.0258,  0.0683,  0.1801, -0.0652, -0.0696, -0.0210, -0.0980, -0.8997]),\n",
       " tensor(-0.8997))"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset[5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-12T03:56:58.605780Z",
     "start_time": "2021-12-12T03:56:58.600486Z"
    }
   },
   "outputs": [],
   "source": [
    "train_loader = DataLoader(dataset=train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "valid_loader = DataLoader(dataset=valid_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "test_loader = DataLoader(dataset=test_dataset, batch_size=BATCH_SIZE, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-12T03:56:58.644302Z",
     "start_time": "2021-12-12T03:56:58.609040Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "embeddings shape on PyTroch :  torch.Size([32, 128])\n",
      "labels shape on PyTroch :  torch.Size([32])\n"
     ]
    }
   ],
   "source": [
    "dataiter = iter(train_loader)\n",
    "embeddings, labels = dataiter.next()\n",
    "\n",
    "print('embeddings shape on PyTroch : ', embeddings.size())\n",
    "print('labels shape on PyTroch : ', labels.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-12T03:56:58.652697Z",
     "start_time": "2021-12-12T03:56:58.646160Z"
    }
   },
   "outputs": [],
   "source": [
    "class MLP(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size):\n",
    "        super(MLP, self).__init__()\n",
    "        \n",
    "        def init_weights(m):\n",
    "            if isinstance(m, nn.Linear):\n",
    "                torch.nn.init.xavier_uniform_(m.weight)\n",
    "                m.bias.data.fill_(0.01)\n",
    "        \n",
    "        \n",
    "        self.layers = nn.Sequential(\n",
    "            nn.Linear(input_size, hidden_size),\n",
    "            nn.BatchNorm1d(hidden_size),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(hidden_size, hidden_size),\n",
    "            nn.BatchNorm1d(hidden_size),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(hidden_size, hidden_size),\n",
    "            nn.BatchNorm1d(hidden_size),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(hidden_size, 1)\n",
    "        )\n",
    "        \n",
    "        self.layers.apply(init_weights)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.layers(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-12T03:56:58.668977Z",
     "start_time": "2021-12-12T03:56:58.660281Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=128, out_features=256, bias=True)\n",
      "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU()\n",
      "    (3): Dropout(p=0.5, inplace=False)\n",
      "    (4): Linear(in_features=256, out_features=256, bias=True)\n",
      "    (5): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (6): ReLU()\n",
      "    (7): Dropout(p=0.5, inplace=False)\n",
      "    (8): Linear(in_features=256, out_features=256, bias=True)\n",
      "    (9): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (10): ReLU()\n",
      "    (11): Dropout(p=0.5, inplace=False)\n",
      "    (12): Linear(in_features=256, out_features=1, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model = MLP(embeddings.size()[1], 256)\n",
    "\n",
    "if LOAD_MODEL:\n",
    "    model.load_state_dict(torch.load(PATH))\n",
    "    \n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-12T03:56:58.679747Z",
     "start_time": "2021-12-12T03:56:58.671957Z"
    }
   },
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "scheduler = torch.optim.lr_scheduler.LambdaLR(optimizer=optimizer,\n",
    "                                        lr_lambda=lambda epoch: 0.95 ** epoch,\n",
    "                                        last_epoch=-1,\n",
    "                                        verbose=False)\n",
    "loss_fn = nn.MSELoss() #will calculate RMSE next line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-12T04:32:41.560428Z",
     "start_time": "2021-12-12T03:56:58.683228Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 1, train loss : 1.1220, valid loss : 0.4197\n",
      "epoch : 2, train loss : 0.9354, valid loss : 0.5664\n",
      "epoch : 3, train loss : 0.7728, valid loss : 0.2548\n",
      "epoch : 4, train loss : 0.6577, valid loss : 0.1317\n",
      "epoch : 5, train loss : 0.5564, valid loss : 0.3504\n",
      "epoch : 6, train loss : 0.4709, valid loss : 0.1336\n",
      "epoch : 7, train loss : 0.3768, valid loss : 0.0620\n",
      "epoch : 8, train loss : 0.3434, valid loss : 0.1282\n",
      "epoch : 9, train loss : 0.3006, valid loss : 0.0850\n",
      "epoch : 10, train loss : 0.2867, valid loss : 0.0926\n",
      "epoch : 11, train loss : 0.2562, valid loss : 0.0930\n",
      "epoch : 12, train loss : 0.2480, valid loss : 0.1258\n",
      "epoch : 13, train loss : 0.2421, valid loss : 0.2151\n",
      "epoch : 14, train loss : 0.2410, valid loss : 0.0992\n",
      "epoch : 15, train loss : 0.2326, valid loss : 0.1454\n",
      "epoch : 16, train loss : 0.2223, valid loss : 0.1840\n",
      "epoch : 17, train loss : 0.2269, valid loss : 0.0905\n",
      "epoch : 18, train loss : 0.2276, valid loss : 0.1784\n",
      "epoch : 19, train loss : 0.2366, valid loss : 0.1658\n",
      "epoch : 20, train loss : 0.2415, valid loss : 0.1205\n",
      "epoch : 21, train loss : 0.2226, valid loss : 0.1366\n",
      "epoch : 22, train loss : 0.2088, valid loss : 0.1234\n",
      "epoch : 23, train loss : 0.2114, valid loss : 0.0882\n",
      "epoch : 24, train loss : 0.2098, valid loss : 0.0922\n",
      "epoch : 25, train loss : 0.2232, valid loss : 0.1094\n",
      "epoch : 26, train loss : 0.2276, valid loss : 0.1153\n",
      "epoch : 27, train loss : 0.2192, valid loss : 0.1372\n",
      "epoch : 28, train loss : 0.2104, valid loss : 0.1428\n",
      "epoch : 29, train loss : 0.2062, valid loss : 0.2272\n",
      "epoch : 30, train loss : 0.2237, valid loss : 0.1772\n",
      "epoch : 31, train loss : 0.2247, valid loss : 0.0636\n",
      "epoch : 32, train loss : 0.2183, valid loss : 0.1488\n",
      "epoch : 33, train loss : 0.2077, valid loss : 0.0831\n",
      "epoch : 34, train loss : 0.2105, valid loss : 0.1568\n",
      "epoch : 35, train loss : 0.1977, valid loss : 0.1288\n",
      "epoch : 36, train loss : 0.2158, valid loss : 0.0656\n",
      "epoch : 37, train loss : 0.2035, valid loss : 0.1633\n",
      "epoch : 38, train loss : 0.2050, valid loss : 0.1303\n",
      "epoch : 39, train loss : 0.2024, valid loss : 0.0417\n",
      "epoch : 40, train loss : 0.2134, valid loss : 0.1387\n",
      "epoch : 41, train loss : 0.2075, valid loss : 0.1197\n",
      "epoch : 42, train loss : 0.2083, valid loss : 0.1178\n",
      "epoch : 43, train loss : 0.2232, valid loss : 0.2408\n",
      "epoch : 44, train loss : 0.2178, valid loss : 0.1829\n",
      "epoch : 45, train loss : 0.2017, valid loss : 0.0691\n",
      "epoch : 46, train loss : 0.2123, valid loss : 0.1001\n",
      "epoch : 47, train loss : 0.2111, valid loss : 0.1409\n",
      "epoch : 48, train loss : 0.2035, valid loss : 0.2013\n",
      "epoch : 49, train loss : 0.2129, valid loss : 0.1115\n",
      "epoch : 50, train loss : 0.2267, valid loss : 0.1352\n",
      "epoch : 51, train loss : 0.2183, valid loss : 0.0919\n",
      "epoch : 52, train loss : 0.2060, valid loss : 0.2209\n",
      "epoch : 53, train loss : 0.2063, valid loss : 0.0656\n",
      "epoch : 54, train loss : 0.2063, valid loss : 0.1566\n",
      "epoch : 55, train loss : 0.2028, valid loss : 0.1524\n",
      "epoch : 56, train loss : 0.2190, valid loss : 0.0544\n",
      "epoch : 57, train loss : 0.2229, valid loss : 0.1383\n",
      "epoch : 58, train loss : 0.2095, valid loss : 0.0832\n",
      "epoch : 59, train loss : 0.2289, valid loss : 0.1696\n",
      "epoch : 60, train loss : 0.2112, valid loss : 0.0873\n",
      "epoch : 61, train loss : 0.2010, valid loss : 0.1701\n",
      "epoch : 62, train loss : 0.2165, valid loss : 0.0947\n",
      "epoch : 63, train loss : 0.1994, valid loss : 0.1095\n",
      "epoch : 64, train loss : 0.2126, valid loss : 0.0996\n",
      "epoch : 65, train loss : 0.1781, valid loss : 0.1443\n",
      "epoch : 66, train loss : 0.2001, valid loss : 0.0901\n",
      "epoch : 67, train loss : 0.2177, valid loss : 0.0891\n",
      "epoch : 68, train loss : 0.2091, valid loss : 0.1005\n",
      "epoch : 69, train loss : 0.2183, valid loss : 0.1213\n",
      "epoch : 70, train loss : 0.2161, valid loss : 0.0972\n",
      "epoch : 71, train loss : 0.1788, valid loss : 0.1245\n",
      "epoch : 72, train loss : 0.2136, valid loss : 0.1105\n",
      "epoch : 73, train loss : 0.2272, valid loss : 0.1140\n",
      "epoch : 74, train loss : 0.1899, valid loss : 0.1348\n",
      "epoch : 75, train loss : 0.2078, valid loss : 0.1688\n",
      "epoch : 76, train loss : 0.2097, valid loss : 0.1559\n",
      "epoch : 77, train loss : 0.2247, valid loss : 0.1748\n",
      "epoch : 78, train loss : 0.2064, valid loss : 0.0970\n",
      "epoch : 79, train loss : 0.1982, valid loss : 0.0876\n",
      "epoch : 80, train loss : 0.2059, valid loss : 0.1513\n",
      "epoch : 81, train loss : 0.1924, valid loss : 0.0940\n",
      "epoch : 82, train loss : 0.2286, valid loss : 0.0574\n",
      "epoch : 83, train loss : 0.1915, valid loss : 0.1489\n",
      "epoch : 84, train loss : 0.2127, valid loss : 0.1564\n",
      "epoch : 85, train loss : 0.1961, valid loss : 0.1315\n",
      "epoch : 86, train loss : 0.2063, valid loss : 0.0552\n",
      "epoch : 87, train loss : 0.2044, valid loss : 0.1204\n",
      "epoch : 88, train loss : 0.2016, valid loss : 0.1571\n",
      "epoch : 89, train loss : 0.1982, valid loss : 0.1249\n",
      "epoch : 90, train loss : 0.2170, valid loss : 0.1173\n",
      "epoch : 91, train loss : 0.1935, valid loss : 0.2135\n",
      "epoch : 92, train loss : 0.1921, valid loss : 0.0950\n",
      "epoch : 93, train loss : 0.2008, valid loss : 0.1212\n",
      "epoch : 94, train loss : 0.2150, valid loss : 0.1352\n",
      "epoch : 95, train loss : 0.2221, valid loss : 0.2164\n",
      "epoch : 96, train loss : 0.2101, valid loss : 0.2144\n",
      "epoch : 97, train loss : 0.2074, valid loss : 0.1787\n",
      "epoch : 98, train loss : 0.2132, valid loss : 0.1788\n",
      "epoch : 99, train loss : 0.2010, valid loss : 0.1293\n",
      "epoch : 100, train loss : 0.1968, valid loss : 0.1309\n",
      "epoch : 101, train loss : 0.1937, valid loss : 0.1709\n",
      "epoch : 102, train loss : 0.2027, valid loss : 0.1908\n",
      "epoch : 103, train loss : 0.2080, valid loss : 0.1394\n",
      "epoch : 104, train loss : 0.1946, valid loss : 0.0979\n",
      "epoch : 105, train loss : 0.2157, valid loss : 0.1246\n",
      "epoch : 106, train loss : 0.1913, valid loss : 0.1515\n",
      "epoch : 107, train loss : 0.2030, valid loss : 0.1061\n",
      "epoch : 108, train loss : 0.1924, valid loss : 0.1471\n",
      "epoch : 109, train loss : 0.2156, valid loss : 0.1355\n",
      "epoch : 110, train loss : 0.1947, valid loss : 0.1700\n",
      "epoch : 111, train loss : 0.2018, valid loss : 0.0965\n",
      "epoch : 112, train loss : 0.2097, valid loss : 0.1138\n",
      "epoch : 113, train loss : 0.1971, valid loss : 0.2137\n",
      "epoch : 114, train loss : 0.1977, valid loss : 0.0896\n",
      "epoch : 115, train loss : 0.2141, valid loss : 0.1253\n",
      "epoch : 116, train loss : 0.1928, valid loss : 0.2351\n",
      "epoch : 117, train loss : 0.2085, valid loss : 0.1305\n",
      "epoch : 118, train loss : 0.1878, valid loss : 0.1103\n",
      "epoch : 119, train loss : 0.1932, valid loss : 0.0512\n",
      "epoch : 120, train loss : 0.1924, valid loss : 0.1839\n",
      "epoch : 121, train loss : 0.2054, valid loss : 0.1745\n",
      "epoch : 122, train loss : 0.2093, valid loss : 0.1818\n",
      "epoch : 123, train loss : 0.1976, valid loss : 0.1273\n",
      "epoch : 124, train loss : 0.2007, valid loss : 0.1613\n",
      "epoch : 125, train loss : 0.2005, valid loss : 0.1540\n",
      "epoch : 126, train loss : 0.1905, valid loss : 0.1638\n",
      "epoch : 127, train loss : 0.2070, valid loss : 0.0781\n",
      "epoch : 128, train loss : 0.2147, valid loss : 0.1251\n",
      "epoch : 129, train loss : 0.2076, valid loss : 0.1115\n",
      "epoch : 130, train loss : 0.2038, valid loss : 0.1023\n",
      "epoch : 131, train loss : 0.2185, valid loss : 0.0794\n",
      "epoch : 132, train loss : 0.2067, valid loss : 0.2414\n",
      "epoch : 133, train loss : 0.1983, valid loss : 0.1221\n",
      "epoch : 134, train loss : 0.2035, valid loss : 0.1314\n",
      "epoch : 135, train loss : 0.2195, valid loss : 0.1005\n",
      "epoch : 136, train loss : 0.1928, valid loss : 0.0719\n",
      "epoch : 137, train loss : 0.2010, valid loss : 0.1125\n",
      "epoch : 138, train loss : 0.2003, valid loss : 0.1281\n",
      "epoch : 139, train loss : 0.1897, valid loss : 0.1294\n",
      "epoch : 140, train loss : 0.1934, valid loss : 0.1420\n",
      "epoch : 141, train loss : 0.1983, valid loss : 0.0295\n",
      "epoch : 142, train loss : 0.1978, valid loss : 0.1516\n",
      "epoch : 143, train loss : 0.2026, valid loss : 0.1550\n",
      "epoch : 144, train loss : 0.2023, valid loss : 0.0870\n",
      "epoch : 145, train loss : 0.1895, valid loss : 0.1786\n",
      "epoch : 146, train loss : 0.1982, valid loss : 0.1437\n",
      "epoch : 147, train loss : 0.2190, valid loss : 0.1415\n",
      "epoch : 148, train loss : 0.1997, valid loss : 0.1078\n",
      "epoch : 149, train loss : 0.1945, valid loss : 0.1158\n",
      "epoch : 150, train loss : 0.2039, valid loss : 0.0751\n",
      "epoch : 151, train loss : 0.1993, valid loss : 0.1225\n",
      "epoch : 152, train loss : 0.1900, valid loss : 0.1457\n",
      "epoch : 153, train loss : 0.1852, valid loss : 0.1981\n",
      "epoch : 154, train loss : 0.2030, valid loss : 0.0521\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 155, train loss : 0.2143, valid loss : 0.1175\n",
      "epoch : 156, train loss : 0.1822, valid loss : 0.1181\n",
      "epoch : 157, train loss : 0.1987, valid loss : 0.1160\n",
      "epoch : 158, train loss : 0.2175, valid loss : 0.1084\n",
      "epoch : 159, train loss : 0.2026, valid loss : 0.1036\n",
      "epoch : 160, train loss : 0.1905, valid loss : 0.1428\n",
      "epoch : 161, train loss : 0.1896, valid loss : 0.0493\n",
      "epoch : 162, train loss : 0.2041, valid loss : 0.1152\n",
      "epoch : 163, train loss : 0.2035, valid loss : 0.1298\n",
      "epoch : 164, train loss : 0.1983, valid loss : 0.1653\n",
      "epoch : 165, train loss : 0.1970, valid loss : 0.1029\n",
      "epoch : 166, train loss : 0.1964, valid loss : 0.1444\n",
      "epoch : 167, train loss : 0.1994, valid loss : 0.1231\n",
      "epoch : 168, train loss : 0.2126, valid loss : 0.1298\n",
      "epoch : 169, train loss : 0.2147, valid loss : 0.0549\n",
      "epoch : 170, train loss : 0.1944, valid loss : 0.1754\n",
      "epoch : 171, train loss : 0.1982, valid loss : 0.0653\n",
      "epoch : 172, train loss : 0.1988, valid loss : 0.2090\n",
      "epoch : 173, train loss : 0.2083, valid loss : 0.1096\n",
      "epoch : 174, train loss : 0.1885, valid loss : 0.0413\n",
      "epoch : 175, train loss : 0.2095, valid loss : 0.1648\n",
      "epoch : 176, train loss : 0.2007, valid loss : 0.0968\n",
      "epoch : 177, train loss : 0.2062, valid loss : 0.1787\n",
      "epoch : 178, train loss : 0.1992, valid loss : 0.1644\n",
      "epoch : 179, train loss : 0.2102, valid loss : 0.1276\n",
      "epoch : 180, train loss : 0.1997, valid loss : 0.0414\n",
      "epoch : 181, train loss : 0.2048, valid loss : 0.0739\n",
      "epoch : 182, train loss : 0.1857, valid loss : 0.1245\n",
      "epoch : 183, train loss : 0.1973, valid loss : 0.1374\n",
      "epoch : 184, train loss : 0.1841, valid loss : 0.1491\n",
      "epoch : 185, train loss : 0.1987, valid loss : 0.0993\n",
      "epoch : 186, train loss : 0.1894, valid loss : 0.1583\n",
      "epoch : 187, train loss : 0.1926, valid loss : 0.1819\n",
      "epoch : 188, train loss : 0.1863, valid loss : 0.0845\n",
      "epoch : 189, train loss : 0.1904, valid loss : 0.1100\n",
      "epoch : 190, train loss : 0.2034, valid loss : 0.0804\n",
      "epoch : 191, train loss : 0.1997, valid loss : 0.1688\n",
      "epoch : 192, train loss : 0.2103, valid loss : 0.1277\n",
      "epoch : 193, train loss : 0.1814, valid loss : 0.1655\n",
      "epoch : 194, train loss : 0.1988, valid loss : 0.1331\n",
      "epoch : 195, train loss : 0.1966, valid loss : 0.1903\n",
      "epoch : 196, train loss : 0.2073, valid loss : 0.0681\n",
      "epoch : 197, train loss : 0.2063, valid loss : 0.1703\n",
      "epoch : 198, train loss : 0.1887, valid loss : 0.1433\n",
      "epoch : 199, train loss : 0.2156, valid loss : 0.1464\n",
      "epoch : 200, train loss : 0.2036, valid loss : 0.0819\n"
     ]
    }
   ],
   "source": [
    "mean_train_losses = []\n",
    "mean_valid_losses = []\n",
    "valid_acc_list = []\n",
    "epochs = 200\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    \n",
    "    train_losses = []\n",
    "    valid_losses = []\n",
    "    for i, (embeddings, labels) in enumerate(train_loader):\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        outputs = model(embeddings)\n",
    "        \n",
    "        #print(\"Embeddings: \", embeddings, \" Output: \", outputs, \" Labels: \", labels.view(-1,1))\n",
    "        \n",
    "        loss = torch.sqrt(loss_fn(outputs, labels.view(-1,1)))\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        train_losses.append(loss.item())\n",
    "            \n",
    "    model.eval()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for i, (embeddings, labels) in enumerate(valid_loader):\n",
    "            outputs = model(embeddings)\n",
    "            loss = torch.sqrt(loss_fn(outputs, labels.view(-1,1)))\n",
    "            \n",
    "            valid_losses.append(loss.item())\n",
    "            \n",
    "    mean_train_losses.append(np.mean(train_losses))\n",
    "    mean_valid_losses.append(np.mean(valid_losses))\n",
    "    \n",
    "    print('epoch : {}, train loss : {:.4f}, valid loss : {:.4f}'\\\n",
    "         .format(epoch+1, np.mean(train_losses), np.mean(valid_losses)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-12T04:32:41.568398Z",
     "start_time": "2021-12-12T04:32:41.562240Z"
    }
   },
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), \"models/struct_graph2vec_MLP_with_dropout_555_v2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-12T04:32:41.864596Z",
     "start_time": "2021-12-12T04:32:41.572341Z"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.plot(mean_train_losses, label='train')\n",
    "ax.plot(mean_valid_losses, label='valid')\n",
    "lines, labels = ax.get_legend_handles_labels()\n",
    "ax.legend(lines, labels, loc='best')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-12T04:34:07.132523Z",
     "start_time": "2021-12-12T04:34:06.272934Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average test loss: 0.7155973528112684\n",
      "average valid loss: 0.133898440430473\n",
      "average train loss: 0.22487263983326422\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "test_losses = []\n",
    "for i, (embeddings, labels) in enumerate(test_loader):\n",
    "    \n",
    "    pred = model(embeddings)\n",
    "    loss = torch.sqrt(loss_fn(pred, labels.view(-1,1)))\n",
    "    #print(\"Prediction:\", pred.detach().numpy(), \" Ground Truth:\", labels.view(-1,1))\n",
    "    test_losses.append(loss.item())\n",
    "print(\"average test loss:\", np.mean(test_losses))\n",
    "print(\"average valid loss:\", np.mean(mean_valid_losses))\n",
    "print(\"average train loss:\", np.mean(mean_train_losses))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### dropout - 0.5 0.4 0.3\n",
    "average test loss : 0.8960558686937604\n",
    "\n",
    "### dropout - 0.5 0.5 0.5\n",
    "average test loss: 0.7127244898251125\n",
    "\n",
    "### dropout - 0.5 0.4 0.4 ***\n",
    "average test loss: 0.7077930867671967\n",
    "average valid loss: 0.1189367274461048\n",
    "average train loss: 0.19893869627302266"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
